{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c2a8e8",
   "metadata": {},
   "source": [
    "# Lesson 3. TF‑IDF: from raw counts to meaningful weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf700fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c8777",
   "metadata": {},
   "source": [
    "## 1) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178b927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Finance wants to compare actuals versus budget for Q3.',\n",
    "          'The analytics team needs clean data before the board meeting.',\n",
    "          'Please consolidate invoices and send a summary by Friday.',\n",
    "          'We need headcount approval before posting the new role.',\n",
    "          'Logistics reported delays at the Rotterdam port this week.',\n",
    "          'Procurement requested three quotes for the same supplier batch.',\n",
    "          'The client asked for a revised scope and updated timeline.',\n",
    "          'We are over budget; include risk notes in the report.',\n",
    "          'Legal needs a redline of the latest contract draft.',\n",
    "          'The CFO wants a dashboard of KPIs for monthly close.',\n",
    "          'The ERP migration requires a full data reconciliation.',\n",
    "          'Sales says the pipeline slipped due to seasonality.',\n",
    "          'HR will update the payroll rules for contractors.',\n",
    "          'The integration team is validating the chart of accounts.',\n",
    "          'We should create a runbook for the month-end process.',\n",
    "          'Please archive outdated SOPs and tag the current versions.',\n",
    "          'Support escalated a P1 incident affecting invoices.',\n",
    "          'The forecasting model needs recalibration after the merger.',\n",
    "          'Security flagged a misconfigured S3 bucket in staging.',\n",
    "          'The PMO wants standardized status updates every Tuesday.',\n",
    "          'Our vendor portal requires multi-factor authentication next month.',\n",
    "          'Please normalize currency values to USD before analysis.',\n",
    "          'We need to document acceptance criteria for the new feature.',\n",
    "          'Stakeholders asked for scenario analysis on OPEX reduction.',\n",
    "          'The BI refresh failed due to a broken data source.',\n",
    "          'We should anonymize PII fields prior to sharing the dataset.',\n",
    "          'Cash flow projections must include deferred revenue.',\n",
    "          'The auditor requested evidence for three random samples.',\n",
    "          'We plan to A/B test the onboarding flow next release.',\n",
    "          'Please schedule a retrospective to capture learnings.']\n",
    "\n",
    "# To DO: print the length of the corpus, and the first five sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a860f8",
   "metadata": {},
   "source": [
    "## 2) Why TF-IDF? \n",
    "\n",
    "We'll construct TF-IDF in small steps on a list of 30 sentences (called \"corpus\") so the maths is clear.\n",
    "\n",
    "\n",
    "### Terminology\n",
    "\n",
    "- **TF (term frequency)** – how often a word (i.e. a term) appears in a document (i.e. a sentence).  \n",
    "  We’ll use a **length-normalised** version:  \n",
    "  $$\n",
    "  \\mathrm{TF}(t, d) = \\frac{\\text{count of term }t\\text{ in document }d}{\\text{total number of terms in document }d}\n",
    "  $$\n",
    "\n",
    "- **DF (document frequency)** – in how many documents (sentences) a term appears.\n",
    "\n",
    "- **IDF (inverse document frequency)** – a log penalty for terms common across many docs:  \n",
    "  $$\n",
    "  \\mathrm{IDF}(t) = \\log\\!\\left(\\frac{1 + N}{1 + \\mathrm{df}(t)}\\right) + 1\n",
    "  $$\n",
    "  where **N** is the total number of documents and **df(t)** is the number of documents containing term *t*.  \n",
    "\n",
    "\n",
    "### Putting it together\n",
    "\n",
    "The **TF-IDF weight** for a given term *t* in document (sentence) *d* is:\n",
    "\n",
    "$$\n",
    "\\mathrm{TF\\!-\\!IDF}(t, d) = \\mathrm{TF}(t, d) \\times \\mathrm{IDF}(t)\n",
    "$$\n",
    "\n",
    "Intuitively:\n",
    "- **TF** measures how important a word is within one document (sentence).\n",
    "- **IDF** reduces the influence of words that appear in every document.\n",
    "- Together they highlight words that are **frequent in this document but rare in others**.\n",
    "\n",
    "\n",
    "**Example intuition:**\n",
    "\n",
    "| Word | Appears in sentence | Appears across all sentences | TF | IDF | TF×IDF |\n",
    "|------|----------------|--------------------|----|-----|--------|\n",
    "| “finance” | 3 times | 20 docs | **TO DO** | low | **TO DO** |\n",
    "| “overrun” | 2 times | 1 doc  | medium | **TO DO** | **high** |\n",
    "| “the” | 8 times | 30 docs | **TO DO** | very low | **TO DO** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f6e9d-5468-4695-9b7d-ef52ea7f2698",
   "metadata": {},
   "source": [
    "## 3) Applying TF-IDF on a very small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a4950f-cd08-4ddd-bb07-650d253e88ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toy_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m toy_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe budget overrun in the finance report\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinance wants actuals versus budget\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistics report delayed this week\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m toy_tokens \u001b[38;5;66;03m# TO DO: tokenise by a simple split on lowercase words\u001b[39;00m\n\u001b[0;32m     10\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m({w \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m toy_tokens \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m doc})\n\u001b[0;32m     11\u001b[0m idx \u001b[38;5;241m=\u001b[39m {w:i \u001b[38;5;28;01mfor\u001b[39;00m i,w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vocab)}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'toy_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "toy_docs = [\n",
    "    \"the budget overrun in the finance report\",\n",
    "    \"finance wants actuals versus budget\",\n",
    "    \"logistics report delayed this week\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "toy_tokens # TO DO: tokenise by a simple split on lowercase words\n",
    "vocab = sorted({w for doc in toy_tokens for w in doc})\n",
    "idx = {w:i for i,w in enumerate(vocab)}\n",
    "\n",
    "# Count matrix: rows=docs, cols=terms\n",
    "X_counts_toy = np.zeros((len(toy_docs), len(vocab)), dtype=int)\n",
    "for r, doc in enumerate(toy_tokens):\n",
    "    c = Counter(doc)\n",
    "    for w, cnt in c.items():\n",
    "        X_counts_toy[r, idx[w]] = cnt\n",
    "\n",
    "print(\"Vocab:\", vocab)\n",
    "print(\"Counts matrix shape:\", X_counts_toy.shape)\n",
    "X_counts_toy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2b7b3c-827f-479b-82a8-b1cde82bba79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_counts_toy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Length-normalised Term frequency (TF): count / total words in the doc\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m doc_lengths \u001b[38;5;241m=\u001b[39m X_counts_toy\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m TF_toy \u001b[38;5;241m=\u001b[39m X_counts_toy \u001b[38;5;241m/\u001b[39m doc_lengths\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF for doc 0 (pairs term:tf):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_counts_toy' is not defined"
     ]
    }
   ],
   "source": [
    "# Length-normalised Term frequency (TF): count / total words in the doc\n",
    "doc_lengths #TO DO: get the count of each document\n",
    "TF_toy = X_counts_toy / doc_lengths\n",
    "print(\"TF for doc 0 (pairs term:tf):\")\n",
    "[(vocab[j], float(TF_toy[0, j])) for j in np.where(TF_toy[0]>0)[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ea9aca-984e-4048-85c5-4ddb25f1070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term  DF  IDF\n",
      "   actuals   1   1.693\n",
      "    budget   2   1.288\n",
      "   delayed   1   1.693\n",
      "   finance   2   1.288\n",
      "        in   1   1.693\n",
      " logistics   1   1.693\n",
      "   overrun   1   1.693\n",
      "    report   2   1.288\n",
      "       the   1   1.693\n",
      "      this   1   1.693\n",
      "    versus   1   1.693\n",
      "     wants   1   1.693\n",
      "      week   1   1.693\n"
     ]
    }
   ],
   "source": [
    "DF_toy = # TO DO: count in how many documents each term appears\n",
    "N = X_counts_toy.shape[0]\n",
    "IDF_toy = #TO DO: apply inverse doc frequency formula from section 2 (log is the natural log, not base 10)\n",
    "\n",
    "pairs = list(zip(vocab, DF_toy.tolist(), IDF_toy.tolist()))\n",
    "print(\"Term  DF  IDF\")\n",
    "for t, df, idf in pairs:\n",
    "    print(f\"{t:>10} {df:>3} {idf:7.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b764a1-6d62-454f-a8e5-0355eee58418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in doc 0 by TF-IDF (unnormalised):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 0.4837563373028415),\n",
       " ('in', 0.24187816865142076),\n",
       " ('overrun', 0.24187816865142076),\n",
       " ('budget', 0.18395458177882582),\n",
       " ('finance', 0.18395458177882582),\n",
       " ('report', 0.18395458177882582)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_toy = TF_toy * IDF_toy  \n",
    "doc_id = 0\n",
    "top = sorted([(vocab[j], TFIDF_toy[doc_id, j]) \n",
    "              for j in np.where(TFIDF_toy[doc_id]>0)[0]],\n",
    "             key=lambda x: x[1], reverse=True)\n",
    "print(\"Top terms in doc 0 by TF-IDF (unnormalised):\") # TO DO: try to explain why it's called \"unnormalised\"\n",
    "top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422ed8e",
   "metadata": {},
   "source": [
    "## 4) Build CountVectorizer and TfidfVectorizer using the sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc85b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 151), (30, 151))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = # TO DO: build count vectorizer \n",
    "tfidf_vec = # TO DO: build tf-idf vectorizer \n",
    "\n",
    "X_count = count_vec.fit_transform(corpus)\n",
    "X_tfidf = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "X_count.shape, X_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40763724",
   "metadata": {},
   "source": [
    "## 5) Compare cosine similarities (Count vs TF‑IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60f6860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 30), (30, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_count = #TO DO: build cosine similarity on X_count \n",
    "sim_tfidf = #TO DO: build cosine similarity on X_tfidf\n",
    "\n",
    "sim_count.shape, sim_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef54943",
   "metadata": {},
   "source": [
    "## 6) most_similar(query, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c893765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, vectorizer, matrix, top_k=3):\n",
    "    q = vectorizer.transform([query])\n",
    "    sims = # TO DO: build cosine similarity between new query and existing matrix \n",
    "    order = np.argsort(sims)[::-1][:top_k]\n",
    "    return [(int(i), float(sims[i])) for i in order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fe131",
   "metadata": {},
   "source": [
    "## 7) Try a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15423e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(7, 0.6708203932499369), (0, 0.3779644730092272), (26, 0.20412414523193154)],\n",
       " [(7, 0.6380323079056135),\n",
       "  (0, 0.37276955975969706),\n",
       "  (26, 0.17746134360673713)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"We are over budget, include this in the finance report\"\n",
    "top_count = # TO DO: apply most_similar function on count vectorizer \n",
    "top_tfidf = # TO DO: apply most_similar function on tf-idf vectorizer\n",
    "top_count, top_tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
