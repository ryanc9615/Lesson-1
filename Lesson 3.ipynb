{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c2a8e8",
   "metadata": {},
   "source": [
    "# Lesson 3. TF‑IDF: from raw counts to meaningful weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf700fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c8777",
   "metadata": {},
   "source": [
    "## 1) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178b927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Finance wants to compare actuals versus budget for Q3.',\n",
    "          'The analytics team needs clean data before the board meeting.',\n",
    "          'Please consolidate invoices and send a summary by Friday.',\n",
    "          'We need headcount approval before posting the new role.',\n",
    "          'Logistics reported delays at the Rotterdam port this week.',\n",
    "          'Procurement requested three quotes for the same supplier batch.',\n",
    "          'The client asked for a revised scope and updated timeline.',\n",
    "          'We are over budget; include risk notes in the report.',\n",
    "          'Legal needs a redline of the latest contract draft.',\n",
    "          'The CFO wants a dashboard of KPIs for monthly close.',\n",
    "          'The ERP migration requires a full data reconciliation.',\n",
    "          'Sales says the pipeline slipped due to seasonality.',\n",
    "          'HR will update the payroll rules for contractors.',\n",
    "          'The integration team is validating the chart of accounts.',\n",
    "          'We should create a runbook for the month-end process.',\n",
    "          'Please archive outdated SOPs and tag the current versions.',\n",
    "          'Support escalated a P1 incident affecting invoices.',\n",
    "          'The forecasting model needs recalibration after the merger.',\n",
    "          'Security flagged a misconfigured S3 bucket in staging.',\n",
    "          'The PMO wants standardized status updates every Tuesday.',\n",
    "          'Our vendor portal requires multi-factor authentication next month.',\n",
    "          'Please normalize currency values to USD before analysis.',\n",
    "          'We need to document acceptance criteria for the new feature.',\n",
    "          'Stakeholders asked for scenario analysis on OPEX reduction.',\n",
    "          'The BI refresh failed due to a broken data source.',\n",
    "          'We should anonymize PII fields prior to sharing the dataset.',\n",
    "          'Cash flow projections must include deferred revenue.',\n",
    "          'The auditor requested evidence for three random samples.',\n",
    "          'We plan to A/B test the onboarding flow next release.',\n",
    "          'Please schedule a retrospective to capture learnings.']\n",
    "\n",
    "# To DO: print the length of the corpus, and the first five sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a860f8",
   "metadata": {},
   "source": [
    "## 2) Why TF-IDF? \n",
    "\n",
    "We'll construct TF-IDF in small steps on a list of 30 sentences (called \"corpus\") so the maths is clear.\n",
    "\n",
    "\n",
    "### Terminology\n",
    "\n",
    "- **TF (term frequency)** – how often a word (i.e. a term) appears in a document (i.e. a sentence).  \n",
    "  We’ll use a **length-normalised** version:  \n",
    "  $$\n",
    "  \\mathrm{TF}(t, d) = \\frac{\\text{count of term }t\\text{ in document }d}{\\text{total number of terms in document }d}\n",
    "  $$\n",
    "\n",
    "- **DF (document frequency)** – in how many documents (sentences) a term appears.\n",
    "\n",
    "- **IDF (inverse document frequency)** – a log penalty for terms common across many docs:  \n",
    "  $$\n",
    "  \\mathrm{IDF}(t) = \\log\\!\\left(\\frac{1 + N}{1 + \\mathrm{df}(t)}\\right) + 1\n",
    "  $$\n",
    "  where **N** is the total number of documents and **df(t)** is the number of documents containing term *t*.  \n",
    "\n",
    "\n",
    "### Putting it together\n",
    "\n",
    "The **TF-IDF weight** for a given term *t* in document (sentence) *d* is:\n",
    "\n",
    "$$\n",
    "\\mathrm{TF\\!-\\!IDF}(t, d) = \\mathrm{TF}(t, d) \\times \\mathrm{IDF}(t)\n",
    "$$\n",
    "\n",
    "Intuitively:\n",
    "- **TF** measures how important a word is within one document (sentence).\n",
    "- **IDF** reduces the influence of words that appear in every document.\n",
    "- Together they highlight words that are **frequent in this document but rare in others**.\n",
    "\n",
    "\n",
    "**Example intuition:**\n",
    "\n",
    "| Word | Appears in sentence | Appears across all sentences | TF | IDF | TF×IDF |\n",
    "|------|----------------|--------------------|----|-----|--------|\n",
    "| “finance” | 3 times | 20 docs | **TO DO** | low | **TO DO** |\n",
    "| “overrun” | 2 times | 1 doc  | medium | **TO DO** | **high** |\n",
    "| “the” | 8 times | 30 docs | **TO DO** | very low | **TO DO** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f6e9d-5468-4695-9b7d-ef52ea7f2698",
   "metadata": {},
   "source": [
    "## 3) Applying TF-IDF on a very small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a4950f-cd08-4ddd-bb07-650d253e88ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['actuals', 'budget', 'delayed', 'finance', 'in', 'logistics', 'overrun', 'report', 'the', 'this', 'versus', 'wants', 'week']\n",
      "Counts matrix shape: (3, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_docs = [\n",
    "    \"the budget overrun in the finance report\",\n",
    "    \"finance wants actuals versus budget\",\n",
    "    \"logistics report delayed this week\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "toy_tokens = [doc.lower().split() for doc in toy_docs]# TO DO: tokenise by a simple split on lowercase words\n",
    "vocab = sorted({w for doc in toy_tokens for w in doc})\n",
    "idx = {w:i for i,w in enumerate(vocab)}\n",
    "\n",
    "# Count matrix: rows=docs, cols=terms\n",
    "X_counts_toy = np.zeros((len(toy_docs), len(vocab)), dtype=int)\n",
    "for r, doc in enumerate(toy_tokens):\n",
    "    c = Counter(doc)\n",
    "    for w, cnt in c.items():\n",
    "        X_counts_toy[r, idx[w]] = cnt\n",
    "\n",
    "print(\"Vocab:\", vocab)\n",
    "print(\"Counts matrix shape:\", X_counts_toy.shape)\n",
    "X_counts_toy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2b7b3c-827f-479b-82a8-b1cde82bba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF for doc 0 (pairs term:tf):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('budget', 0.14285714285714285),\n",
       " ('finance', 0.14285714285714285),\n",
       " ('in', 0.14285714285714285),\n",
       " ('overrun', 0.14285714285714285),\n",
       " ('report', 0.14285714285714285),\n",
       " ('the', 0.2857142857142857)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length-normalised Term frequency (TF): count / total words in the doc\n",
    "doc_lengths = X_counts_toy.sum(axis=1, keepdims=True)#TO DO: get the count of each document\n",
    "TF_toy = X_counts_toy / doc_lengths\n",
    "print(\"TF for doc 0 (pairs term:tf):\")\n",
    "[(vocab[j], float(TF_toy[0, j])) for j in np.where(TF_toy[0]>0)[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ea9aca-984e-4048-85c5-4ddb25f1070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term  DF  IDF\n",
      "   actuals   1   1.099\n",
      "    budget   2   0.405\n",
      "   delayed   1   1.099\n",
      "   finance   2   0.405\n",
      "        in   1   1.099\n",
      " logistics   1   1.099\n",
      "   overrun   1   1.099\n",
      "    report   2   0.405\n",
      "       the   1   1.099\n",
      "      this   1   1.099\n",
      "    versus   1   1.099\n",
      "     wants   1   1.099\n",
      "      week   1   1.099\n"
     ]
    }
   ],
   "source": [
    "DF_toy = np.count_nonzero(X_counts_toy > 0, axis=0) # TO DO: count in how many documents each term appears\n",
    "N = X_counts_toy.shape[0]\n",
    "IDF_toy = np.log(N / DF_toy) #TO DO: apply inverse doc frequency formula from section 2 (log is the natural log, not base 10)\n",
    "\n",
    "pairs = list(zip(vocab, DF_toy.tolist(), IDF_toy.tolist()))\n",
    "print(\"Term  DF  IDF\")\n",
    "for t, df, idf in pairs:\n",
    "    print(f\"{t:>10} {df:>3} {idf:7.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b764a1-6d62-454f-a8e5-0355eee58418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in doc 0 by TF-IDF (unnormalised):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', np.float64(0.31388922533374564)),\n",
       " ('in', np.float64(0.15694461266687282)),\n",
       " ('overrun', np.float64(0.15694461266687282)),\n",
       " ('budget', np.float64(0.05792358687259491)),\n",
       " ('finance', np.float64(0.05792358687259491)),\n",
       " ('report', np.float64(0.05792358687259491))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_toy = TF_toy * IDF_toy  \n",
    "doc_id = 0\n",
    "top = sorted([(vocab[j], TFIDF_toy[doc_id, j]) \n",
    "              for j in np.where(TFIDF_toy[doc_id]>0)[0]],\n",
    "             key=lambda x: x[1], reverse=True)\n",
    "print(\"Top terms in doc 0 by TF-IDF (unnormalised):\") # TO DO: try to explain why it's called \"unnormalised\"\n",
    "top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422ed8e",
   "metadata": {},
   "source": [
    "## 4) Build CountVectorizer and TfidfVectorizer using the sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc85b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 178), (30, 178))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(lowercase=True) # TO DO: build count vectorizer \n",
    "tfidf_vec = TfidfVectorizer(lowercase=True)# TO DO: build tf-idf vectorizer \n",
    "\n",
    "X_count = count_vec.fit_transform(corpus)\n",
    "X_tfidf = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "X_count.shape, X_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40763724",
   "metadata": {},
   "source": [
    "## 5) Compare cosine similarities (Count vs TF‑IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60f6860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 30), (30, 30))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_count = cosine_similarity(X_count)#TO DO: build cosine similarity on X_count \n",
    "sim_tfidf = cosine_similarity(X_tfidf)#TO DO: build cosine similarity on X_tfidf\n",
    "\n",
    "sim_count.shape, sim_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef54943",
   "metadata": {},
   "source": [
    "## 6) most_similar(query, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c893765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, vectorizer, matrix, top_k=3):\n",
    "    q = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(q, matrix).flatten()# TO DO: build cosine similarity between new query and existing matrix \n",
    "    order = np.argsort(sims)[::-1][:top_k]\n",
    "    return [(int(i), float(sims[i])) for i in order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fe131",
   "metadata": {},
   "source": [
    "## 7) Try a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15423e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(7, 0.7999999999999999),\n",
       "  (14, 0.21081851067789195),\n",
       "  (28, 0.21081851067789195)],\n",
       " [(7, 0.7486225529710736), (0, 0.23813860693437672), (4, 0.14037177217188426)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"We are over budget, include this in the finance report\"\n",
    "top_count = most_similar(query, count_vec, X_count, top_k=3) # TO DO: apply most_similar function on count vectorizer \n",
    "top_tfidf = most_similar(query, tfidf_vec, X_tfidf, top_k=3)# TO DO: apply most_similar function on tf-idf vectorizer\n",
    "top_count, top_tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
