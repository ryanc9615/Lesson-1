{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7a895",
   "metadata": {},
   "source": [
    "# Lesson 1: Text Basics: Tokenisation, n‑grams, Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cfbda",
   "metadata": {},
   "source": [
    "**Goal:** build intuition by tokenising text, making n‑grams, and plotting frequencies on a ~50‑sentence business dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3b922-53b7-4cdb-be42-37d82cf11eaf",
   "metadata": {},
   "source": [
    "> You'll fill in the `# TODO` parts while sharing your screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a8f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "texts = ['The new ERP rollout improved our monthly reporting speed by 40 percent.', 'Customer support response time is slow but the knowledge base is helpful.', 'Weekly sales increased after the email campaign and discount codes.', 'Our invoice reconciliation still takes too long despite the automation.', 'The dashboard is clean, but export to Excel sometimes breaks.', 'Warehouse picking errors dropped once barcodes were introduced.', 'Marketing wants a way to tag and search proposals across clients.', 'Cash flow forecasting is better, although the model drifts each quarter.', 'We migrated the CRM without issues; user training was the hardest part.', 'Late supplier deliveries cause stockouts and unhappy customers.', 'Finance wants to compare actuals vs budget by region on one page.', 'Legal needs a quick search for similar contract clauses.', 'The Slack bot that summarizes meetings saves everyone time.', 'Holiday season traffic overloaded our API rate limits last year.', 'Managers ask for a weekly PDF with key KPIs and anomalies.', 'Sales reps complain that leads are stale by the time they call.', 'The procurement team built a simple approval workflow in Sheets.', 'Our service desk tickets spike after each product release.', 'The BI team wants ownership of all production dashboards.', 'We track NPS monthly but the comments are hard to triage.', 'Accounting wants to tag expenses with project codes automatically.', 'The logistics team wants a daily SMS when shipments are delayed.', 'Retail partners send price lists in different formats every quarter.', \"The HR portal search is poor; people can't find policies quickly.\", 'Website conversions improved when we simplified the checkout page.', 'Security wants automated alerts for suspicious logins out of hours.', 'The pricing model needs to factor in currency volatility.', 'Suppliers keep changing SKUs which breaks our catalog import.', 'Revenue operations wants one source of truth for pipeline stages.', 'The help center needs a better way to surface duplicate questions.', 'Users asked for dark mode and better keyboard shortcuts.', 'We should archive old contracts and keep only the latest version.', 'The forecasting spreadsheet crashes when the dataset exceeds 50k rows.', 'QA wants a daily digest of failed test cases grouped by component.', 'The field sales team needs offline access to the product brochure.', 'The team wants to track trial-to-paid conversion by cohort.', 'Data entry errors happen when people copy from PDFs into Excel.', 'Projects get delayed because stakeholders approve documents late.', 'We need a faster way to find similar customer complaints.', 'Finance wants bank feeds to reconcile automatically overnight.', 'The board pack preparation takes three days every month.', 'The SEO team wants to compare rankings by region and device.', 'The training team needs a library of reusable lesson templates.', 'Warehouse staff want to scan returns and print labels in one step.', 'Customer success wants churn risk scores inside the CRM.', 'Support needs a smart reply assistant for common questions.', 'The expense policy changed; employees need an easy explainer.', 'Legal wants a tool to search for similar indemnity clauses.', 'IT wants a report of unused SaaS seats to reduce costs.', 'Partners ask for a portal to check order status in real time.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0161e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    'the','a','an','and','or','but','to','of','in','on','for','by','with','is','are','was','were',\n",
    "    'our','we','it','that','this','those','these','as','at','from','without','once','each','across',\n",
    "    'still','too','vs','one','last','year','sometimes','once','although','over','into','out','when',\n",
    "    'every','very','out','off','after','before','can','t','s','re','ll','d','should','could','would'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351017fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str):\n",
    "    tokens = text.split()\n",
    "    return [t for t in tokens if t not in STOPWORDS]\n",
    "\n",
    "def make_ngrams(tokens, n=2):\n",
    "    return list(zip(*[tokens[i:] for i in range(n)]))\n",
    "\n",
    "def top_n(counter: Counter, n=15):\n",
    "    return list(islice(counter.most_common(), n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45722bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bar(items, title, xlabel, ylabel):\n",
    "    labels = [' '.join(k) if isinstance(k, tuple) else k for k, _ in items]\n",
    "    counts = [v for _, v in items]\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.bar(range(len(labels)), counts)\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b52236",
   "metadata": {},
   "source": [
    "## 1) DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ed427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...  #TO DO: load into pandas dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25fa5b",
   "metadata": {},
   "source": [
    "## 2) Clean + tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = ...  # TO DO: tokenize the cleaned text \n",
    "df[['text','tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403dd94",
   "metadata": {},
   "source": [
    "## 3) Unigram frequencies + plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71352e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_tokens = ...  # sum(df['tokens'].tolist(), [])\n",
    "uni_counts = # TO DO: a counter on all_tokens\n",
    "top_uni = top_n(uni_counts, 15)\n",
    "top_uni[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de5be61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...  # TO DO: plot bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95917d2b",
   "metadata": {},
   "source": [
    "## 4) Bigrams & trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bigram_counts = Counter()\n",
    "for toks in df['tokens']:\n",
    "    bigs = ...  # TO DO: make the 2-grams\n",
    "    bigram_counts.update(bigs)\n",
    "\n",
    "top_bi = top_n(bigram_counts, 15)\n",
    "top_bi[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1864cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "...  # TO DO: make a plot bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c204d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = Counter()\n",
    "for toks in df['tokens']:\n",
    "    tris = ...  # TO DO: make the 3-grams\n",
    "    trigram_counts.update(tris)\n",
    "\n",
    "top_tri = top_n(trigram_counts, 15)\n",
    "top_tri[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde747bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "...  # TO DO: plot bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890886e",
   "metadata": {},
   "source": [
    "## 5) KWIC — Keyword in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1588a",
   "metadata": {},
   "source": [
    "KWIC prints each occurrence of a keyword together with a few words around it (the *context window*). It lets you inspect *how* a word is used.\n",
    "\n",
    "**Task:** implement `kwic(term, window=3)` and try words like `wants`, `search`, `weekly`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kwic(term, window=3):\n",
    "    term = term.lower()\n",
    "    for sent in texts:\n",
    "        cleaned = clean_text(sent)\n",
    "        toks = cleaned.split()\n",
    "        for i,t in enumerate(toks):\n",
    "            if t == term:\n",
    "                left = ' '.join(toks[max(0,i-window):i])\n",
    "                right = ' '.join(toks[i+1:i+1+window])\n",
    "                print(f\"... {left} [{t}] {right} ...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
